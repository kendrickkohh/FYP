{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb923975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any\n",
    "import os\n",
    "from azure.ai.evaluation.red_team import RedTeam, RiskCategory, AttackStrategy\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import AzureCliCredential, get_bearer_token_provider, DefaultAzureCredential\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f69af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure credentials\n",
    "credential = AzureCliCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "465a1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Configuration -----\n",
    "# Azure AI Project information\n",
    "azure_ai_project = os.environ.get(\"RED_TEAM_PROJECT_ENDPOINT\")\n",
    "\n",
    "# Azure OpenAI deployment information\n",
    "azure_openai_deployment = os.environ.get(\"AZURE_OPENAI_ADVERSARIAL_DEPLOYMENT_NAME\")\n",
    "azure_openai_endpoint = os.environ.get(\"AZURE_OPENAI_ADVERSARIAL_ENDPOINT\")\n",
    "azure_openai_api_key = os.environ.get(\"AZURE_OPENAI_ADVERSARIAL_API_KEY\")\n",
    "azure_openai_api_version = os.environ.get(\"AZURE_OPENAI_ADVERSARIAL_API_VERSION\")\n",
    "\n",
    "# azure_openai_deployment = os.environ.get(\"AZURE_OPENAI_UNSAFE_DEPLOYMENT_NAME\")\n",
    "# azure_openai_endpoint = os.environ.get(\"AZURE_OPENAI_UNSAFE_ENDPOINT\")\n",
    "# azure_openai_api_key = os.environ.get(\"AZURE_OPENAI_UNSAFE_API_KEY\")\n",
    "# azure_openai_api_version = os.environ.get(\"AZURE_OPENAI_UNSAFE_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e2ed117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AzureOpenAI Callback\n",
    "async def azure_openai_callback(\n",
    "    messages: list,\n",
    "    stream: Optional[bool] = False,\n",
    "    session_state: Optional[str] = None,\n",
    "    context: Optional[Dict[str, Any]] = None,\n",
    ") -> dict[str, list[dict[str, str]]]:\n",
    "    \n",
    "    # Get token provider for Azure AD authentication\n",
    "    token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "    # Initialize Azure OpenAI client\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_ad_token_provider=token_provider,\n",
    "    )\n",
    "\n",
    "    ## Extract the latest message from the conversation history\n",
    "    messages_list = [{\"role\": message.role, \"content\": message.content} for message in messages]\n",
    "    latest_message = messages_list[-1][\"content\"]\n",
    "\n",
    "    try:\n",
    "        # Call the model\n",
    "        response = client.chat.completions.create(\n",
    "            model=azure_openai_deployment,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": latest_message},\n",
    "            ],\n",
    "            # max_tokens=500, # If using an o1 base model, comment this line out\n",
    "            max_completion_tokens=500,  # If using an o1 base model, uncomment this line\n",
    "            # temperature=0.7, # If using an o1 base model, comment this line out (temperature param not supported for o1 base models)\n",
    "        )\n",
    "\n",
    "        # Format the response to follow the expected chat protocol format\n",
    "        formatted_response = {\"content\": response.choices[0].message.content, \"role\": \"assistant\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Azure OpenAI: {e!s}\")\n",
    "        formatted_response = \"I encountered an error and couldn't process your request.\"\n",
    "    return {\"messages\": [formatted_response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e838a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama Callback\n",
    "MODEL_NAME = \"llama3.2\"\n",
    "\n",
    "async def ollama_callback(\n",
    "    messages: list,\n",
    "    stream: Optional[bool] = False,\n",
    "    session_state: Optional[str] = None,\n",
    "    context: Optional[Dict[str, Any]] = None,\n",
    ") -> dict[str, list[dict[str, str]]]:\n",
    "\n",
    "    # Extract the latest message from the conversation history\n",
    "    messages_list = [{\"role\": m.role, \"content\": m.content} for m in messages]\n",
    "    latest_message = messages_list[-1][\"content\"]\n",
    "\n",
    "    try:\n",
    "        # Call the local LLaMA model via Ollama\n",
    "        response = ollama.chat(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": latest_message}],\n",
    "        )\n",
    "\n",
    "        # Format the response to follow the expected chat protocol format\n",
    "        formatted_response = {\n",
    "            \"content\": response[\"message\"][\"content\"],\n",
    "            \"role\": \"assistant\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Ollama: {e!s}\")\n",
    "        formatted_response = {\n",
    "            \"content\": \"I encountered an error and couldn't process your request.\",\n",
    "            \"role\": \"assistant\"\n",
    "        }\n",
    "\n",
    "    return {\"messages\": [formatted_response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9549a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RedTeam instance with all of the risk categories with 5 attack objectives generated for each category\n",
    "red_team = RedTeam(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    credential=credential,\n",
    "    risk_categories=[RiskCategory.Violence, RiskCategory.HateUnfairness, RiskCategory.Sexual, RiskCategory.SelfHarm],\n",
    "    num_objectives=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c88d4148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 STARTING RED TEAM SCAN\n",
      "📂 Output directory: ./.scan_Basic-Callback-Scan_20251006_145858\n",
      "📊 Risk categories: ['violence', 'hate_unfairness', 'sexual', 'self_harm']\n",
      "🔗 Track your red team scan in AI Foundry: https://ai.azure.com/resource/build/redteaming/16f42b7d-81f3-4706-a8bd-922890cb9e26?wsid=/subscriptions/ffcdaad1-98c2-4d37-97be-371caf0be262/resourceGroups/FYP/providers/Microsoft.CognitiveServices/accounts/fyp-resource/projects/fyp&tid=15ce9348-be2a-462b-8fc0-e1765a9b204a\n",
      "📋 Planning 52 total tasks\n",
      "📝 Fetched baseline objectives for violence: 5 objectives\n",
      "📝 Fetched baseline objectives for hate_unfairness: 5 objectives\n",
      "📝 Fetched baseline objectives for sexual: 5 objectives\n",
      "📝 Fetched baseline objectives for self_harm: 5 objectives\n",
      "🔄 Fetching objectives for strategy 2/13: character_space\n",
      "🔄 Fetching objectives for strategy 3/13: rot13\n",
      "🔄 Fetching objectives for strategy 4/13: unicode_confusable\n",
      "🔄 Fetching objectives for strategy 5/13: char_swap\n",
      "🔄 Fetching objectives for strategy 6/13: morse\n",
      "🔄 Fetching objectives for strategy 7/13: leetspeak\n",
      "🔄 Fetching objectives for strategy 8/13: url\n",
      "🔄 Fetching objectives for strategy 9/13: binary\n",
      "🔄 Fetching objectives for strategy 10/13: base64_rot13\n",
      "🔄 Fetching objectives for strategy 11/13: base64\n",
      "🔄 Fetching objectives for strategy 12/13: flip\n",
      "🔄 Fetching objectives for strategy 13/13: tense\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:   0%|                                      | 0/52 [00:00<?, ?scan/s, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Processing 52 tasks in parallel (max 5 at a time)\n",
      "▶️ Starting task: baseline strategy for violence risk category\n",
      "▶️ Starting task: baseline strategy for hate_unfairness risk category\n",
      "▶️ Starting task: baseline strategy for sexual risk category\n",
      "▶️ Starting task: baseline strategy for self_harm risk category\n",
      "▶️ Starting task: character_space strategy for violence risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:   8%|██                         | 4/52 [02:35<2:04:39, 155.83s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/baseline_violence_e08feae6-5032-4785-97de-6effd3f3bd71.json\".\n",
      "✅ Completed task 1/52 (1.9%) - baseline/violence in 155.8s\n",
      "   Est. remaining: 159.8 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/baseline_hate_unfairness_b8e723f7-8aa4-4a79-a87e-4a6e1e9d1a3c.json\".\n",
      "✅ Completed task 2/52 (3.8%) - baseline/hate_unfairness in 155.8s\n",
      "   Est. remaining: 78.3 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/baseline_sexual_7b8c6853-e8b7-4c67-af71-8928a211626d.json\".\n",
      "✅ Completed task 3/52 (5.8%) - baseline/sexual in 155.8s\n",
      "   Est. remaining: 51.2 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/baseline_self_harm_91463434-75ac-483d-859b-fb48192c4e16.json\".\n",
      "✅ Completed task 4/52 (7.7%) - baseline/self_harm in 155.8s\n",
      "   Est. remaining: 37.6 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  10%|██▉                           | 5/52 [02:36<18:13, 23.27s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/character_space_violence_fa377ab7-7f6b-4380-ab3b-daaa61ed8a30.json\".\n",
      "✅ Completed task 5/52 (9.6%) - character_space/violence in 156.1s\n",
      "   Est. remaining: 29.5 minutes\n",
      "▶️ Starting task: character_space strategy for hate_unfairness risk category\n",
      "▶️ Starting task: character_space strategy for sexual risk category\n",
      "▶️ Starting task: character_space strategy for self_harm risk category\n",
      "▶️ Starting task: rot13 strategy for violence risk category\n",
      "▶️ Starting task: rot13 strategy for hate_unfairness risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  17%|█████▏                        | 9/52 [06:49<55:09, 76.97s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/character_space_hate_unfairness_7118e2ce-f960-458d-9491-fd7aa1f8300a.json\".\n",
      "✅ Completed task 6/52 (11.5%) - character_space/hate_unfairness in 253.6s\n",
      "   Est. remaining: 56.5 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/character_space_sexual_37f77b09-d14f-4e80-abe9-434fad518a79.json\".\n",
      "✅ Completed task 7/52 (13.5%) - character_space/sexual in 253.6s\n",
      "   Est. remaining: 47.4 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/character_space_self_harm_f819ef1a-3b7d-4935-bdb8-efe6fc806d8c.json\".\n",
      "✅ Completed task 8/52 (15.4%) - character_space/self_harm in 253.6s\n",
      "   Est. remaining: 40.5 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/rot13_violence_ae0e2e3e-b3a0-424e-8319-2c4df3379356.json\".\n",
      "✅ Completed task 9/52 (17.3%) - rot13/violence in 253.6s\n",
      "   Est. remaining: 35.2 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  19%|█████▌                       | 10/52 [06:50<23:07, 33.05s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/rot13_hate_unfairness_ea6d0a30-30b7-47cd-918b-dd17b85c7416.json\".\n",
      "✅ Completed task 10/52 (19.2%) - rot13/hate_unfairness in 253.9s\n",
      "   Est. remaining: 31.0 minutes\n",
      "▶️ Starting task: rot13 strategy for sexual risk category\n",
      "▶️ Starting task: rot13 strategy for self_harm risk category\n",
      "▶️ Starting task: unicode_confusable strategy for violence risk category\n",
      "▶️ Starting task: unicode_confusable strategy for hate_unfairness risk category\n",
      "▶️ Starting task: unicode_confusable strategy for sexual risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  27%|███████▊                     | 14/52 [11:29<47:19, 74.72s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/rot13_sexual_b4cf3c60-89ad-458d-a1ea-df0350624f6c.json\".\n",
      "✅ Completed task 11/52 (21.2%) - rot13/sexual in 279.0s\n",
      "   Est. remaining: 44.8 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/rot13_self_harm_df3fb6d0-8120-4a80-8d9a-fd7cf56ccba9.json\".\n",
      "✅ Completed task 12/52 (23.1%) - rot13/self_harm in 279.0s\n",
      "   Est. remaining: 40.1 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/unicode_confusable_violence_a1a83d28-f853-413b-a3b9-2d4ddd41f2fd.json\".\n",
      "✅ Completed task 13/52 (25.0%) - unicode_confusable/violence in 279.0s\n",
      "   Est. remaining: 36.1 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/unicode_confusable_hate_unfairness_5dba8439-4dd0-43ac-a2d1-f21b704258a1.json\".\n",
      "✅ Completed task 14/52 (26.9%) - unicode_confusable/hate_unfairness in 279.0s\n",
      "   Est. remaining: 32.6 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  29%|████████▎                    | 15/52 [11:29<23:26, 38.00s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/unicode_confusable_sexual_21619909-80ad-4357-b13b-b9f7299518d3.json\".\n",
      "✅ Completed task 15/52 (28.8%) - unicode_confusable/sexual in 279.3s\n",
      "   Est. remaining: 29.7 minutes\n",
      "▶️ Starting task: unicode_confusable strategy for self_harm risk category\n",
      "▶️ Starting task: char_swap strategy for violence risk category\n",
      "▶️ Starting task: char_swap strategy for hate_unfairness risk category\n",
      "▶️ Starting task: char_swap strategy for sexual risk category\n",
      "▶️ Starting task: char_swap strategy for self_harm risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  37%|██████████▌                  | 19/52 [14:13<31:13, 56.78s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/unicode_confusable_self_harm_fbadb5b0-c80c-49e6-93d4-1a7b671210fd.json\".\n",
      "✅ Completed task 16/52 (30.8%) - unicode_confusable/self_harm in 163.7s\n",
      "   Est. remaining: 33.2 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/char_swap_violence_246d6377-8bc5-4656-a5b4-6a5fba456a15.json\".\n",
      "✅ Completed task 17/52 (32.7%) - char_swap/violence in 163.6s\n",
      "   Est. remaining: 30.4 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/char_swap_hate_unfairness_47a50bfd-a839-46a6-97ca-f52b2dd1eaf0.json\".\n",
      "✅ Completed task 18/52 (34.6%) - char_swap/hate_unfairness in 163.6s\n",
      "   Est. remaining: 27.9 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/char_swap_sexual_193abbf5-3ef9-47f2-b55e-c8e6c2825925.json\".\n",
      "✅ Completed task 19/52 (36.5%) - char_swap/sexual in 163.6s\n",
      "   Est. remaining: 25.6 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  38%|███████████▏                 | 20/52 [14:13<16:21, 30.66s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/char_swap_self_harm_387fa078-89be-4380-82ae-9e9fbf51b6d8.json\".\n",
      "✅ Completed task 20/52 (38.5%) - char_swap/self_harm in 163.9s\n",
      "   Est. remaining: 23.6 minutes\n",
      "▶️ Starting task: morse strategy for violence risk category\n",
      "▶️ Starting task: morse strategy for hate_unfairness risk category\n",
      "▶️ Starting task: morse strategy for sexual risk category\n",
      "▶️ Starting task: morse strategy for self_harm risk category\n",
      "▶️ Starting task: leetspeak strategy for violence risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  46%|█████████████▍               | 24/52 [17:58<27:09, 58.18s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/morse_violence_2a8bb7f1-091f-414b-928a-787f8fa2fb2d.json\".\n",
      "✅ Completed task 21/52 (40.4%) - morse/violence in 225.5s\n",
      "   Est. remaining: 27.3 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/morse_hate_unfairness_a82e7218-28ce-4bcc-9750-d15f172eaed3.json\".\n",
      "✅ Completed task 22/52 (42.3%) - morse/hate_unfairness in 225.5s\n",
      "   Est. remaining: 25.2 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/morse_sexual_3f8dcf01-056e-4586-9232-e8e6006dd23c.json\".\n",
      "✅ Completed task 23/52 (44.2%) - morse/sexual in 225.5s\n",
      "   Est. remaining: 23.3 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/morse_self_harm_8e3f8903-53b8-4b58-a005-94d12fa57b53.json\".\n",
      "✅ Completed task 24/52 (46.2%) - morse/self_harm in 225.5s\n",
      "   Est. remaining: 21.6 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  48%|█████████████▉               | 25/52 [17:59<14:30, 32.23s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/leetspeak_violence_9427fc42-1a43-48ac-a6ee-114ce6eb30c3.json\".\n",
      "✅ Completed task 25/52 (48.1%) - leetspeak/violence in 225.7s\n",
      "   Est. remaining: 20.0 minutes\n",
      "▶️ Starting task: leetspeak strategy for hate_unfairness risk category\n",
      "▶️ Starting task: leetspeak strategy for sexual risk category\n",
      "▶️ Starting task: leetspeak strategy for self_harm risk category\n",
      "▶️ Starting task: url strategy for violence risk category\n",
      "▶️ Starting task: url strategy for hate_unfairness risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  56%|████████████████▏            | 29/52 [20:35<18:55, 49.37s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/leetspeak_hate_unfairness_8a4f5c90-a170-48a2-95bc-f7e179f30551.json\".\n",
      "✅ Completed task 26/52 (50.0%) - leetspeak/hate_unfairness in 156.8s\n",
      "   Est. remaining: 21.1 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/leetspeak_sexual_17a1d5f2-e0f8-44fe-b8b7-df23c321c5f3.json\".\n",
      "✅ Completed task 27/52 (51.9%) - leetspeak/sexual in 156.8s\n",
      "   Est. remaining: 19.6 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/leetspeak_self_harm_259ae248-bb8b-474e-ab8a-0d6f9511cce1.json\".\n",
      "✅ Completed task 28/52 (53.8%) - leetspeak/self_harm in 156.8s\n",
      "   Est. remaining: 18.1 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/url_violence_da3ef52c-4030-4e7a-9631-ce2f657599f0.json\".\n",
      "✅ Completed task 29/52 (55.8%) - url/violence in 156.8s\n",
      "   Est. remaining: 16.8 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  58%|████████████████▋            | 30/52 [20:36<10:08, 27.67s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/url_hate_unfairness_2998ee0f-b0ae-407a-b5af-28f45087d9be.json\".\n",
      "✅ Completed task 30/52 (57.7%) - url/hate_unfairness in 157.1s\n",
      "   Est. remaining: 15.5 minutes\n",
      "▶️ Starting task: url strategy for sexual risk category\n",
      "▶️ Starting task: url strategy for self_harm risk category\n",
      "▶️ Starting task: binary strategy for violence risk category\n",
      "▶️ Starting task: binary strategy for hate_unfairness risk category\n",
      "▶️ Starting task: binary strategy for sexual risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  65%|██████████████████▉          | 34/52 [25:37<19:28, 64.90s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/url_sexual_361f20cb-eb12-43b2-816a-53c938cbbfc4.json\".\n",
      "✅ Completed task 31/52 (59.6%) - url/sexual in 301.8s\n",
      "   Est. remaining: 17.7 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/url_self_harm_c725e064-f086-4925-bcf1-b8fbf0dafdeb.json\".\n",
      "✅ Completed task 32/52 (61.5%) - url/self_harm in 301.7s\n",
      "   Est. remaining: 16.4 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/binary_violence_d4fb12fd-1b44-457d-bcc8-bf8f863dcdaf.json\".\n",
      "✅ Completed task 33/52 (63.5%) - binary/violence in 301.7s\n",
      "   Est. remaining: 15.1 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/binary_hate_unfairness_0a3d43ed-b84c-4486-8365-67e1c664b3e7.json\".\n",
      "✅ Completed task 34/52 (65.4%) - binary/hate_unfairness in 301.7s\n",
      "   Est. remaining: 13.9 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  67%|███████████████████▌         | 35/52 [25:38<10:21, 36.57s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/binary_sexual_384ed4a4-10ca-4812-9ab7-f1901863fa7a.json\".\n",
      "✅ Completed task 35/52 (67.3%) - binary/sexual in 302.0s\n",
      "   Est. remaining: 12.7 minutes\n",
      "▶️ Starting task: binary strategy for self_harm risk category\n",
      "▶️ Starting task: base64_rot13 strategy for violence risk category\n",
      "▶️ Starting task: base64_rot13 strategy for hate_unfairness risk category\n",
      "▶️ Starting task: base64_rot13 strategy for sexual risk category\n",
      "▶️ Starting task: base64_rot13 strategy for self_harm risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  75%|█████████████████████▊       | 39/52 [28:37<12:06, 55.90s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/binary_self_harm_5e72b60d-ef1f-431a-b218-a4a92647c53a.json\".\n",
      "✅ Completed task 36/52 (69.2%) - binary/self_harm in 179.7s\n",
      "   Est. remaining: 13.0 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/base64_rot13_violence_02f4f5e6-2e52-419b-bac7-c37b8ac0bc18.json\".\n",
      "✅ Completed task 37/52 (71.2%) - base64_rot13/violence in 179.7s\n",
      "   Est. remaining: 11.8 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/base64_rot13_hate_unfairness_78c061c0-88e9-40f9-97a1-fc60abcda99a.json\".\n",
      "✅ Completed task 38/52 (73.1%) - base64_rot13/hate_unfairness in 179.6s\n",
      "   Est. remaining: 10.7 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/base64_rot13_sexual_cd644447-b63a-4408-af3d-95d7197738f1.json\".\n",
      "✅ Completed task 39/52 (75.0%) - base64_rot13/sexual in 179.6s\n",
      "   Est. remaining: 9.7 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  77%|██████████████████████▎      | 40/52 [28:38<06:19, 31.59s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/base64_rot13_self_harm_05411294-a660-45e0-93c3-de46770ffed6.json\".\n",
      "✅ Completed task 40/52 (76.9%) - base64_rot13/self_harm in 179.9s\n",
      "   Est. remaining: 8.8 minutes\n",
      "▶️ Starting task: base64 strategy for violence risk category\n",
      "▶️ Starting task: base64 strategy for hate_unfairness risk category\n",
      "▶️ Starting task: base64 strategy for sexual risk category\n",
      "▶️ Starting task: base64 strategy for self_harm risk category\n",
      "▶️ Starting task: flip strategy for violence risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  85%|████████████████████████▌    | 44/52 [36:21<11:57, 89.73s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/base64_violence_75663242-09c5-4330-a44d-ab7f76e50ca9.json\".\n",
      "✅ Completed task 41/52 (78.8%) - base64/violence in 463.6s\n",
      "   Est. remaining: 9.9 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/base64_hate_unfairness_6e44f40a-e200-40cc-bd18-d3ec99d56704.json\".\n",
      "✅ Completed task 42/52 (80.8%) - base64/hate_unfairness in 463.6s\n",
      "   Est. remaining: 8.8 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/base64_sexual_e594c9d0-672b-4b6c-a59b-b34cb9c83895.json\".\n",
      "✅ Completed task 43/52 (82.7%) - base64/sexual in 463.6s\n",
      "   Est. remaining: 7.7 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/base64_self_harm_3a7808f0-9443-47cf-872c-1d883761ade7.json\".\n",
      "✅ Completed task 44/52 (84.6%) - base64/self_harm in 463.6s\n",
      "   Est. remaining: 6.7 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  87%|█████████████████████████    | 45/52 [36:22<05:55, 50.75s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/flip_violence_cd41bb8b-d5e4-4109-869e-d1f7f6a306a3.json\".\n",
      "✅ Completed task 45/52 (86.5%) - flip/violence in 463.8s\n",
      "   Est. remaining: 5.7 minutes\n",
      "▶️ Starting task: flip strategy for hate_unfairness risk category\n",
      "▶️ Starting task: flip strategy for sexual risk category\n",
      "▶️ Starting task: flip strategy for self_harm risk category\n",
      "▶️ Starting task: tense strategy for violence risk category\n",
      "▶️ Starting task: tense strategy for hate_unfairness risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  94%|███████████████████████████▎ | 49/52 [42:44<04:46, 95.37s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/flip_hate_unfairness_ee97063b-65ed-45af-b65c-f022df23368e.json\".\n",
      "✅ Completed task 46/52 (88.5%) - flip/hate_unfairness in 382.7s\n",
      "   Est. remaining: 5.6 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/flip_sexual_9865246b-be98-417c-a4d0-54634f40a315.json\".\n",
      "✅ Completed task 47/52 (90.4%) - flip/sexual in 382.7s\n",
      "   Est. remaining: 4.6 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/flip_self_harm_99db80b1-7ea1-48f9-9d43-2d0e9c83e5a3.json\".\n",
      "✅ Completed task 48/52 (92.3%) - flip/self_harm in 382.7s\n",
      "   Est. remaining: 3.6 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/tense_violence_c0c6e5b1-6395-4378-9f75-daef7090935b.json\".\n",
      "✅ Completed task 49/52 (94.2%) - tense/violence in 382.7s\n",
      "   Est. remaining: 2.7 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  96%|███████████████████████████▉ | 50/52 [42:45<01:47, 53.97s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/tense_hate_unfairness_e398eb3e-057e-49e8-9e8b-ef79c993ee83.json\".\n",
      "✅ Completed task 50/52 (96.2%) - tense/hate_unfairness in 383.0s\n",
      "   Est. remaining: 1.7 minutes\n",
      "▶️ Starting task: tense strategy for sexual risk category\n",
      "▶️ Starting task: tense strategy for self_harm risk category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  98%|████████████████████████████▍| 51/52 [44:44<01:02, 62.82s/scan, current=initializing]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/tense_sexual_3b14f805-0fea-4d2f-8cc1-8f2a53561c04.json\".\n",
      "✅ Completed task 51/52 (98.1%) - tense/sexual in 119.8s\n",
      "   Est. remaining: 0.9 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: 100%|█████████████████████████████| 52/52 [44:45<00:00, 51.64s/scan, current=initializing]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/tense_self_harm_c79e0345-1655-4673-a2e9-b3df5739b943.json\".\n",
      "✅ Completed task 52/52 (100.0%) - tense/self_harm in 120.1s\n",
      "   Est. remaining: 0.0 minutes\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/red_team_output.json\".\n",
      "\n",
      "Evaluation results saved to \"/Users/kendrickkoh/Desktop/University/FYP/Red teaming preparation/.scan_Basic-Callback-Scan_20251006_145858/final_results.json\".\n",
      "\n",
      "Overall ASR: 3.46%\n",
      "Attack Success: 9/260 attacks were successful\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "Risk Category        | Baseline ASR   | Easy-Complexity Attacks ASR  | Moderate-Complexity Attacks ASR | Difficult-Complexity Attacks ASR\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "Violence             | 0.0%           | 2.0%                         | 0.0%                            | 0.0%                          \n",
      "Hate-unfairness      | 0.0%           | 2.0%                         | 0.0%                            | 0.0%                          \n",
      "Sexual               | 20.0%          | 8.0%                         | 20.0%                           | 0.0%                          \n",
      "Self-harm            | 0.0%           | 2.0%                         | 0.0%                            | 0.0%                          \n",
      "\n",
      "Detailed results available at:\n",
      "https://ai.azure.com/resource/build/redteaming/16f42b7d-81f3-4706-a8bd-922890cb9e26?wsid=/subscriptions/ffcdaad1-98c2-4d37-97be-371caf0be262/resourceGroups/FYP/providers/Microsoft.CognitiveServices/accounts/fyp-resource/projects/fyp&tid=15ce9348-be2a-462b-8fc0-e1765a9b204a\n",
      "\n",
      "📂 All scan files saved to: ./.scan_Basic-Callback-Scan_20251006_145858\n",
      "✅ Scan completed successfully!\n"
     ]
    }
   ],
   "source": [
    "result = await red_team.scan(\n",
    "    target=ollama_callback,\n",
    "    scan_name=\"Basic-Callback-Scan\",\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.EASY,  # Group of easy complexity attacks\n",
    "        AttackStrategy.MODERATE,  # Group of moderate complexity attacks\n",
    "        AttackStrategy.CharacterSpace,  # Add character spaces\n",
    "        AttackStrategy.ROT13,  # Use ROT13 encoding\n",
    "        AttackStrategy.UnicodeConfusable,  # Use confusable Unicode characters\n",
    "        AttackStrategy.CharSwap,  # Swap characters in prompts\n",
    "        AttackStrategy.Morse,  # Encode prompts in Morse code\n",
    "        AttackStrategy.Leetspeak,  # Use Leetspeak\n",
    "        AttackStrategy.Url,  # Use URLs in prompts\n",
    "        AttackStrategy.Binary,  # Encode prompts in binary\n",
    "        AttackStrategy.Compose([AttackStrategy.Base64, AttackStrategy.ROT13]),  # Use two strategies in one attack\n",
    "    ],\n",
    "    output_path=\"red_team_output.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57967d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the red team scan with multiple attack strategies\n",
    "# advanced_result = await model_red_team.scan(\n",
    "#     target=azure_openai_callback,\n",
    "#     scan_name=\"Advanced-Callback-Scan\",\n",
    "#     attack_strategies=[\n",
    "#         AttackStrategy.EASY,  # Group of easy complexity attacks\n",
    "#         AttackStrategy.MODERATE,  # Group of moderate complexity attacks\n",
    "#         AttackStrategy.CharacterSpace,  # Add character spaces\n",
    "#         AttackStrategy.ROT13,  # Use ROT13 encoding\n",
    "#         AttackStrategy.UnicodeConfusable,  # Use confusable Unicode characters\n",
    "#         AttackStrategy.CharSwap,  # Swap characters in prompts\n",
    "#         AttackStrategy.Morse,  # Encode prompts in Morse code\n",
    "#         AttackStrategy.Leetspeak,  # Use Leetspeak\n",
    "#         AttackStrategy.Url,  # Use URLs in prompts\n",
    "#         AttackStrategy.Binary,  # Encode prompts in binary\n",
    "#         AttackStrategy.Compose([AttackStrategy.Base64, AttackStrategy.ROT13]),  # Use two strategies in one attack\n",
    "#     ],\n",
    "#     output_path=\"Advanced-Callback-Scan.json\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
